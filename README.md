# japanese_refine

                                                                                 프로젝트명 :      일본어 데이터 정제
                                                                                       이름 :          나윤수, 오상혁
                                                                                     작성일 :             2020-03-09
                                                                                     

1차
=======================================================
####1. 프로젝트 기간 : 2020-03-09 ~ 2020-03-11\

####2. 프로젝트 내용
  * 목표 : 100만줄에 대한 텍스트를 분석하여 ASR에 적합한 데이터로 정제
  
  * 보고사항 : 텍스트 분석 후 보고
    - 데이터 중 괜찮은 텍스트 샘플 및 잘못된 텍스트 샘플 추출. 그에 대한 이유 제시
      (예, 괜찮은 텍스트의 경우 - 주어+목적+동사 배치가 자연스러움, 잘못된 텍스트의 경우 -  문장에서 같은 단어의 반복이 발생함) 
    - 입력 데이터, 정제 python스크립트, 결과물 데이터 제시. 이때 입력 데이터가 제공된 데이터와 차이 없을경우 생략 가능. 

####3. 프로젝트 진행
  1. japanese_news_data 파악
  2. input 데이터에 대한 정제
    - 〆 = しめ로 변경
  3. japanese_news_data 오름차순 정렬
  4. 필요없는 기호 제거
  5. 제거에 필요한 data 규칙 찾기
  6. 문장의 형태가 부족한 문장 제거
  7. 순서를 표시한 특수 문자 제거
  8. 웃음을 의미하는 あ{3,}(3개 이상)제거

####4. 특이사항
  * 괜찮은 데이터와 안 괜찮은 데이터 분류할 것
    * GOOD
      * 적절한 range값 찾기(min~max)
    * BAD
      * 존재하는 모든 특수기호들 파악
      * 반복적인 음절의 특정 개수 파악(n값 찾기)
  
  * 정제 된 데이터에서 \u3000 발생(생성 이유 파악)
  * 길이를 기준으로 sort
  * ppt로 정리
  

2차
=======================================================
####1. 프로젝트 기간 : 2020-03-11 ~ 2020-03-18\

####2. 프로젝트 내용
  * 목표 : 100만줄에 대한 텍스트를 분석하여 ASR에 적합한 데이터로 정제
  
  * 보고사항 : 데이터 정제 후 ppt 정리 후 보고
    - 데이터 중 괜찮은 텍스트 샘플 및 잘못된 텍스트 샘플 추출. 그에 대한 이유 제시
      (예, 괜찮은 텍스트의 경우 - 주어+목적+동사 배치가 자연스러움, 잘못된 텍스트의 경우 -  문장에서 같은 단어의 반복이 발생함) 
    - 입력 데이터, 정제 python스크립트, 결과물 데이터 제시. 이때 입력 데이터가 제공된 데이터와 차이 없을경우 생략 가능. 

####3. 프로젝트 진행
  1. 적절한 range값 찾기(min=8, max=134)
  2. input 데이터에 대한 정제
    - \u3000과 같은 일본어 특유 space 특수기호 제거
  3. 길이를 기준으로 sort
  4. 술어로 끝나는 문장 제거
  5. 구어체로 끝나지 않은 문장 제거

####4. 특이사항
  * 괜찮은 데이터와 안 괜찮은 데이터 분류할 것
    * GOOD
      * 술어로 끝나는 문장 제거 코드화
      * 구어체로 끝나는 문장이 아닌 다른 이유
    * BAD
      * 존재하는 모든 특수기호들 파악
      * 파악된 반복적인 특성을 가진 문자 외 다른 글자들도 코드화   
  
  * ppt로 정리

3차
=======================================================
####1. 프로젝트 기간 : 2020-03-18 ~ 2020-03-23\

####2. 프로젝트 내용
  * 목표 : 100만줄에 대한 텍스트를 분석하여 ASR에 적합한 데이터로 정제
  
  * 보고사항 : 데이터 정제 후 ppt 정리 후 보고
    - 데이터 중 괜찮은 텍스트 샘플 및 잘못된 텍스트 샘플 추출. 그에 대한 이유 제시
      (예, 괜찮은 텍스트의 경우 - 주어+목적+동사 배치가 자연스러움, 잘못된 텍스트의 경우 -  문장에서 같은 단어의 반복이 발생함) 
    - 입력 데이터, 정제 python스크립트, 결과물 데이터 제시. 이때 입력 데이터가 제공된 데이터와 차이 없을경우 생략 가능. 

####3. 프로젝트 진행
  1. ppt 수정
  2. 한자+히라가나, 한자+히라가나+가타카나로 구성되지 않은 문장 제거
  3. 각 글자별 반복적 사용 허용범위 파악 후 코드화
  4. 각 제거한 항목별 제거 Percentage 파악
  5. 그래프화

####4. 특이사항
  * ppt 시각화시 오해 소지 제거
  
4차
=======================================================
####1. 프로젝트 기간 : 2020-03-23 ~ 2020-04-01\

####2. 프로젝트 내용
  * 목표 : 100만줄에 대한 텍스트를 분석하여 ASR에 적합한 데이터로 정제
  
  * 보고사항 : 데이터 정제 후 ppt 정리 후 보고
    - 데이터 중 괜찮은 텍스트 샘플 및 잘못된 텍스트 샘플 추출. 그에 대한 이유 제시
      (예, 괜찮은 텍스트의 경우 - 주어+목적+동사 배치가 자연스러움, 잘못된 텍스트의 경우 -  문장에서 같은 단어의 반복이 발생함) 
    - 입력 데이터, 정제 python스크립트, 결과물 데이터 제시. 이때 입력 데이터가 제공된 데이터와 차이 없을경우 생략 가능. 

####3. 프로젝트 진행
  1. ppt 수정
  2. graph의 오해 소지 제거
  3. ppt 순서 수정
  4. 글자 max 값 기존 573 -> 701로 수정
  
####4. 특이사항
  * 다른 데이터로 돌린 후 추후 피드백 예정
